## 目标

使用 RealsenseD435i 相机, 综合利用点云、图像信息，检测人体目标（要求能够区分照片和真人)

在检测到人形目标后，计算距离、移动速度等指标。 

并区分目标行为，至少包括：站立、坐下、倒地、行走

总结：一种简单的**多目标视频行为检测**任务，需根据3D信息计算距离、移动速度，并作简单的活体检测

## 分析

D435i 可以提供 RGB 图像和深度图像

https://huzhenyou.github.io/blog/2023/08/PoseEstimation-TAD
https://blog.csdn.net/kobepaul123/article/details/126942095

### 1. 检测人体目标+目标追踪

可以使用自顶向下的识别方法，先通过 yolo-v11 利用纯 RGB 信息识别行人，然后将行人提取框在深度图中的对应部分进行深度变化识别，即可区分照片和真人。在检测目标后需增加目标追踪模块，以便后续任务的进行。

**步骤 1.1: 使用YOLO+Track算法进行行人检测**

选择预训练的YOLOv11模型，返回图像中每个检测到的行人的边界框，包含坐标（x1, y1, x2, y2）和置信度。将边界框送入ByteTrack（可选择BoTSORT）中进行目标追踪。
代码在Detector中基于ultralytics的BaseSolution完成。

**步骤 1.2: 提取行人的深度信息**

通过pyrealsense2库，获取相机的深度图像,将YOLO检测框（从RGB图像中获取）投影到深度图像上，提取该区域的深度信息。
对于每个像素位置，深度图会提供相机到该点的距离值（单位：米）, 使用Realsense相机的内参将RGB图像坐标转换为深度图像坐标。

**步骤 1.3: 区分照片和真人**

动态深度变化检测：真实人体的深度信息通常具有较高的连续性和深度变化，而静态图像（例如照片）的深度图通常没有深度变化。可以通过分析图像内的深度变化来进行区分。

深度连续性检查：通过检测提取区域内的深度连续性（例如相邻像素的深度变化幅度），如果深度变化较小且规则，可能是静态照片。如果深度图中存在明显的、不规则的变化，可能是实时的人体。

### 2. 计算距离、移动速度等指标

将深度图映射为 3D 点云，直接计算距离，在帧与帧之间根据点云偏移量计算移动速度

**步骤 2.1: 映射深度图为3D点云**

使用Realsense SDK中的rs2::pointcloud类，将深度图像转换为3D点云。
每个深度图中的像素点对应一个3D空间中的点，可以通过深度值和相机内参将二维图像坐标转换为三维空间坐标。

**步骤 2.2: 计算目标与相机的距离**

提取点云中的目标区域，计算该区域内所有点的平均深度值，得到目标的平均距离。

**步骤 2.3: 计算移动速度**

在每一帧图像中提取目标的3D位置（可以使用检测框中的深度信息），通过比较连续帧中的目标位置变化，计算位移量。

### 3. 目标行为区分

思考使用 MMAction2 内的视频行为识别算法，各类算法都过于复杂，虽可识别几百种人类活动，但没有简单的站立、坐下、倒地、行走，考虑自己构造数据集重新训练

1.FUKinect-Fall 数据集由Kinect V1构建包含动作：行走、弯腰、坐下、蹲下、躺下和跌倒
参与者：21名，年龄范围19-72岁
数据量：总计1008个深度视频，记录了20个关节的3D坐标（x, y, z）
数据结构：6种动作 × 8次重复 × 21名参与者
视频规格：约4-5秒时长，分辨率320×240，30帧每秒

Aslan M., Akbulut Y., Sengor A., CevdetInce M. "Skeleton based efficient fall detection", J. Faculty Eng. Architecture Gazi Univ., 32 (4) (2017), pp. 1025-1034. (DOI: 10.17341/gazimmfd.369347)

可以由FUKinect-Fall再扩充站立类别，然后通过时序网络进行识别，先识别出关节点，再识别出类别

2.AVA 数据集
代表算法SlowFast
python .\demo\demo.py configs/detection/slowfast/slowfast_kinetics400-pretrained-r50_8xb6-8x8x1-cosine-10e_ava22-rgb.py .\checkpoints\slowfast_kinetics400-pretrained-r50_8xb6-8x8x1-cosine-10e_ava22-rgb_20220906-d934a48f.pth .\demo\demo.mp4 tools/data/ava/label_map.txt