## 目的

Realsense D455 カメラを使用し、点群と画像情報を総合的に利用して人体目標を検出し（写真と実物を区別できること）、検出された人体目標について、距離、移動速度などの指標を計算する。さらに、少なくとも立位、座位、倒立、歩行の目標行動を区別する。

要約： 3D情報に基づいて距離、移動速度を計算し、簡単な生体検出を行う多目標ビデオ行動検出タスク。

## 分析

D455 は RGB 画像と深度画像を提供できる。

https://huzhenyou.github.io/blog/2023/08/PoseEstimation-TAD
https://blog.csdn.net/kobepaul123/article/details/126942095

### 1. 人体目標検出 + 目標追跡

トップダウン方式の識別方法を使用できる。まず、YOLO-v11 を用いて純粋な RGB 情報から歩行者を識別し、次に歩行者の抽出されたバウンディングボックスに対応する深度画像の部分で深度変化を識別することで、写真と実物を区別する。目標検出後、後続のタスクのために目標追跡モジュールを追加する必要がある。

**ステップ 1.1: YOLO+Track アルゴリズムを用いた歩行者検出**

事前学習済みの YOLOv11 モデルを選択し、画像内で検出された各歩行者のバウンディングボックス（座標 (x1, y1, x2, y2) と信頼度を含む）を返す。バウンディングボックスを ByteTrack（BoTSORT も選択可能）に送って目標追跡を行う。コードは Detector クラス内で ultralytics の BaseSolution を基に実装する。

**ステップ 1.2: 歩行者の深度情報抽出**

pyrealsense2 ライブラリを通じて、カメラの深度画像を取得する。YOLO 検出ボックス（RGB 画像から取得）を深度画像に投影し、その領域の深度情報を抽出する。各ピクセル位置について、深度画像はカメラからその点までの距離値（単位：メートル）を提供する。Realsense カメラの内部パラメータを使用して、RGB 画像座標を深度画像座標に変換する。

**ステップ 1.3: 写真と実物の区別**

動的深度変化検出: 実物の人体の深度情報は通常、高い連続性と深度変化を示すのに対し、静止画像（写真など）の深度画像には通常、深度変化がない。画像内の深度変化を分析することで区別できる。
深度連続性チェック: 抽出領域内の深度連続性（例えば、隣接するピクセルの深度変化の大きさ）を検出する。深度変化が小さく規則的な場合、静止写真である可能性がある。深度画像に顕著で不規則な変化が存在する場合、リアルタイムの人体である可能性がある。

### 2. 距離、移動速度などの指標計算

深度画像を 3D 点群にマッピングし、直接距離を計算する。フレーム間で点群のオフセットに基づいて移動速度を計算する。

**ステップ 2.1: 深度画像の 3D 点群へのマッピング**

Realsense SDK の rs2::pointcloud クラスを使用して、深度画像を 3D 点群に変換する。深度画像内の各ピクセル点は、3D 空間内の点に対応し、深度値とカメラの内部パラメータを使用して、2D 画像座標を 3D 空間座標に変換できる。

**ステップ 2.2: 目標とカメラの距離計算**

点群から目標領域を抽出し、その領域内のすべての点の平均深度値を計算して、目標の平均距離を得る。

**ステップ 2.3: 移動速度の計算**

各フレーム画像で目標の 3D 位置（検出ボックス内の深度情報を使用できる）を抽出し、連続するフレーム間の目標位置の変化を比較して、変位量を計算する。フレーム間の時間差がわかれば、移動速度を計算できる。

### 3. 目標行動の区別

MMAction2 内のビデオ行動認識アルゴリズムの使用を検討する。しかし、既存の多くのアルゴリズムは複雑すぎるため、単純な立位、座位、倒立、歩行の識別に適したものが少ない。独自にデータセットを構築して再学習することを検討する。

**1.FUKinect-Fall データセット**
Kinect V1 によって構築された、歩行、屈む、座る、しゃがむ、横になる、転倒の動作を含むデータセット。参加者：21名、年齢範囲 19-72 歳。データ量：合計 1008 個の深度ビデオ、20 個の関節の 3D 座標 (x, y, z) を記録。データ構造：6 種類の動作 × 8 回の繰り返し × 21 名の参加者。ビデオ仕様：約 4-5 秒の長さ、解像度 320×240、30 フレーム/秒。

Aslan M., Akbulut Y., Sengor A., CevdetInce M. "Skeleton based efficient fall detection", J. Faculty Eng. Architecture Gazi Univ., 32 (4) (2017), pp. 1025-1034. (DOI: 10.17341/gazimmfd.369347)

FUKinect-Fall データセットに立位のカテゴリを拡張し、時系列ネットワークを通じて識別できる。まず関節点を識別し、次にカテゴリを識別する。

**2.AVA データセット**
代表的なアルゴリズム 「SlowFast」
python .\demo\demo.py
configs/detection/slowfast/slowfast_kinetics400-pretrained-r50_8xb6-8x8x1-cosine-10e_ava22-rgb.py .\checkpoints\slowfast_kinetics400-pretrained-r50_8xb6-8x8x1-cosine-10e_ava22-rgb_20220906-d934a48f.pth .\demo\demo.mp4 tools/data/ava/label_map.txt
